{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab5ce7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, predicted_class):\n",
    "        self.predicted_class = predicted_class  # 预测的类别\n",
    "        self.feature_index = 0  # 特征索引\n",
    "        self.threshold = 0  # 阈值\n",
    "        self.left = None  # 左子树\n",
    "        self.right = None  # 右子树\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None):\n",
    "        self.max_depth = max_depth  # 决策树的最大深度\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes_ = len(set(y))  # 类别的数量\n",
    "        self.n_features_ = X.shape[1]  # 特征的数量\n",
    "        self.tree_ = self._grow_tree(X, y)  # 构建决策树\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(inputs) for inputs in X]  # 对输入数据进行预测\n",
    "    \n",
    "    def _best_gini_split(self, X, y):\n",
    "        m = y.size  # 样本的数量\n",
    "        if m <= 1:  # 如果样本数量小于等于1，无法进行分割\n",
    "            return None, None\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]  # 每个类别在父节点中的样本数量\n",
    "        best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)  # 父节点的基尼指数\n",
    "        best_idx, best_thr = None, None  # 最佳分割特征索引和阈值\n",
    "        for idx in range(self.n_features_):  # 遍历每个特征\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))  # 根据特征值对样本进行排序\n",
    "            num_left = [0] * self.n_classes_  # 左子节点中每个类别的样本数量\n",
    "            num_right = num_parent.copy()  # 右子节点中每个类别的样本数量，初始值为父节点的样本数量\n",
    "            for i in range(1, m):  # 遍历每个样本\n",
    "                c = classes[i - 1]  # 样本的类别\n",
    "                num_left[c] += 1  # 更新左子节点中对应类别的样本数量\n",
    "                num_right[c] -= 1  # 更新右子节点中对应类别的样本数量\n",
    "                gini_left = 1.0 - sum(\n",
    "                    (num_left[x] / i) ** 2 for x in range(self.n_classes_)\n",
    "                )  # 左子节点的基尼指数\n",
    "                gini_right = 1.0 - sum(\n",
    "                    (num_right[x] / (m - i)) ** 2 for x in range(self.n_classes_)\n",
    "                )  # 右子节点的基尼指数\n",
    "                gini = (i * gini_left + (m - i) * gini_right) / m  # 加权平均的基尼指数\n",
    "                if thresholds[i] == thresholds[i - 1]:  # 如果特征值相同，则跳过（特征阈值）\n",
    "                    continue\n",
    "                if gini < best_gini:  # 如果基尼指数更小，则更新最佳分割特征索引和阈值 （循环每个特征，和每个阈值，以求解最优分类\n",
    "                    best_gini = gini\n",
    "                    best_idx = idx\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2\n",
    "        return best_idx, best_thr  # 返回最佳分割特征索引和阈值\n",
    "\n",
    "    def _best_gain_split(self, X, y):\n",
    "        m = y.size  # 样本的数量\n",
    "        if m <= 1:  # 如果样本数量小于等于1，无法进行分割\n",
    "            return None, None\n",
    "        num_parent = [np.sum(y == c) for c in range(self.n_classes_)]  # 计算每个类别的样本数量\n",
    "        best_gain = -1  # 初始化最佳信息增益\n",
    "        best_idx, best_thr = None, None  # 初始化最佳特征索引和阈值\n",
    "        for idx in range(self.n_features_):  # 遍历每个特征\n",
    "            thresholds, classes = zip(*sorted(zip(X[:, idx], y)))  # 对每个特征值和类别标签进行排序\n",
    "            num_left = [0] * self.n_classes_  # 初始化左子树的类别数量 (左边都是0,为0时自动计算为0） \n",
    "            num_right = num_parent.copy()  # 右子树的类别数量初始化为父节点的类别数量 (右边是全部）\n",
    "            for i in range(1, m):  # 遍历每个样本\n",
    "                c = classes[i - 1]  # 获取当前样本的类别\n",
    "                num_left[c] += 1  # 左子树的类别数量增加\n",
    "                num_right[c] -= 1  # 右子树的类别数量减少\n",
    "                entropy_parent = -sum((num / m) * np.log2(num / m) for num in num_parent if num != 0)  # 计算父节点的熵\n",
    "                entropy_left = -sum((num / i) * np.log2(num / i) for num in num_left if num != 0)  # 计算左子树的熵\n",
    "                entropy_right = -sum((num / (m - i)) * np.log2(num / (m - i)) for num in num_right if num != 0)  # 计算右子树的熵\n",
    "                gain = entropy_parent - (i * entropy_left + (m - i) * entropy_right) / m  # 计算信息增益（分类后左右的信息熵最小）\n",
    "                if thresholds[i] == thresholds[i - 1]:  # 如果当前样本的特征值和前一个样本的特征值相同，跳过（不一样才能分界）\n",
    "                    continue\n",
    "                if gain > best_gain:  # 如果当前的信息增益大于最佳信息增益\n",
    "                    best_gain = gain  # 更新最佳信息增益\n",
    "                    best_idx = idx  # 更新最佳特征索引\n",
    "                    best_thr = (thresholds[i] + thresholds[i - 1]) / 2  # 更新最佳阈值 （循环每个样本的值，根据两份数据均值确定阈值，一直循环）\n",
    "        return best_idx, best_thr  # 返回最佳特征索引和阈值\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]  # 计算每个类别的样本数量\n",
    "        predicted_class = np.argmax(num_samples_per_class)  # 预测的类别为样本数量最多的类别 （即确定分到该分支样本最多的记为该类）\n",
    "        node = Node(predicted_class=predicted_class)  # 创建节点\n",
    "        if depth < self.max_depth:  # 如果当前深度小于最大深度\n",
    "            idx, thr = self._best_gain_split(X, y)  # 计算最佳分割\n",
    "            if idx is not None:  # 如果存在最佳分割\n",
    "                indices_left = X[:, idx] < thr  # 左子树的样本索引 (第 idx特征中小于thr阈值的索引)\n",
    "                X_left, y_left = X[indices_left], y[indices_left]  # 左子树的样本\n",
    "                X_right, y_right = X[~indices_left], y[~indices_left]  # 右子树的样本\n",
    "                node.feature_index = idx  # 设置节点的特征索引\n",
    "                node.threshold = thr  # 设置节点的阈值\n",
    "                node.left = self._grow_tree(X_left, y_left, depth + 1)  # 构建左子树\n",
    "                node.right = self._grow_tree(X_right, y_right, depth + 1)  # 构建右子树\n",
    "        return node  # 返回节点\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.tree_  # 获取决策树的根节点\n",
    "        while node.left:  # 如果存在左子树\n",
    "            if inputs[node.feature_index] < node.threshold:  # 如果输入样本的特征值小于阈值\n",
    "                node = node.left  # 到左子树\n",
    "            else:\n",
    "                node = node.right  # 到右子树\n",
    "        return node.predicted_class  # 返回预测的类别\n",
    "\n",
    "# 数据集\n",
    "X = [[25, 1, 30000],\n",
    "     [35, 0, 40000],\n",
    "     [45, 0, 80000],\n",
    "     [20, 1, 10000],\n",
    "     [55, 1, 60000],\n",
    "     [60, 0, 90000],\n",
    "     [30, 1, 50000],\n",
    "     [40, 0, 75000]]\n",
    "\n",
    "Y = [0, 0, 1, 0, 1, 1, 0, 1]\n",
    "\n",
    "# 创建决策树模型\n",
    "clf = DecisionTree(max_depth=2)\n",
    "\n",
    "# 训练模型\n",
    "clf.fit(np.array(X), np.array(Y))\n",
    "\n",
    "# 预测\n",
    "print(clf.predict([[40, 0, 75000],[10, 0, 75000]]))  # 输出：[1, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49b755e3-126d-4878-975b-7732c6733e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zip object at 0x000001EDFEC6CEC0>\n",
      "[(0, 0), (0, 1), (0, 1), (0, 1), (1, 0), (1, 0), (1, 0), (1, 1)]\n",
      "(0, 0) (0, 1) (0, 1) (0, 1) (1, 0) (1, 0) (1, 0) (1, 1)\n",
      "<zip object at 0x000001EDFEC45FC0>\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "X = [[25, 1, 30000],\n",
    "     [35, 0, 40000],\n",
    "     [45, 0, 80000],\n",
    "     [20, 1, 10000],\n",
    "     [55, 1, 60000],\n",
    "     [60, 0, 90000],\n",
    "     [30, 1, 50000],\n",
    "     [40, 0, 75000]]\n",
    "\n",
    "Y = [0, 0, 1, 0, 1, 1, 0, 1]\n",
    "X,y = np.array(X), np.array(Y)\n",
    "\n",
    "print(zip(X[:, idx], y))\n",
    "print(sorted(zip(X[:, idx], y))) # return list\n",
    "print(*sorted(zip(X[:, idx], y))) # unpacks list  print data format is the zip format\n",
    "# print(type(*sorted(zip(X[:, idx], y))))\n",
    "print(zip(*sorted(zip(X[:, idx], y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7eecdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import numpy as np\n",
    "\n",
    "# 数据集\n",
    "X = np.array([[25, 1, 30000],\n",
    "              [35, 0, 40000],\n",
    "              [45, 0, 80000],\n",
    "              [20, 1, 10000],\n",
    "              [55, 1, 60000],\n",
    "              [60, 0, 90000],\n",
    "              [30, 1, 50000],\n",
    "              [40, 0, 75000]])\n",
    "\n",
    "Y = np.array([0, 0, 1, 0, 1, 1, 0, 1])\n",
    "\n",
    "# 创建决策树模型\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# 训练模型\n",
    "clf = clf.fit(X, Y)\n",
    "\n",
    "# 预测\n",
    "print(clf.predict([[40, 0, 75000],[10, 0, 75000]]))  # 输出：[1, 0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
